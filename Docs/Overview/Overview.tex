\section{What is \BoxLib?}

\BoxLib\ is a software library containing all the functionality to write parallel, 
block-structured adaptive mesh refinement (AMR) applications.  \BoxLib\ was developed 
at the Center for Computational Sciences and Engineering (CCSE) at Lawrence Berkeley 
National Laboratory.  Further information can be found by contacting Mike Lijewski 
of CCSE at {\tt MJLijewski@lbl.gov} or by visiting our webpage
at {\tt https://ccse.lbl.gov/}.  Key features of \BoxLib\ include:

\begin{itemize}
\item Support for block-structured AMR with optional subcycling in time
\item Support for cell-centered, face-centered, and nodal data
\item Support for hyperbolic, parabolic, and elliptic solves on hierarchical grid structure
\item C++ and Fortran90 versions
\item Supports hybrid programming model with MPI and OpenMP
\item Basis of mature applications in combustion, astrophysics, cosmology, and porous media
\item Demonstrated scaling of linear solvers to 100,000 processors and 
      hydrodynamics to over 200,000 processors
\item Freely available to interested users on our website
\item The plotfile format generated by \BoxLib\ can be read by {\tt VisIt}, {\tt AmrVis},
      and {\tt yt}.
\end{itemize}

\subsection{Data Structures}

The fundamental parallel abstraction is the \MultiFab\, which holds the data on the 
union of grids at a level.  A \MultiFab\ is composed of fortran array boxes 
(i.e., \FArrayBox\ or \Fab~s); each \Fab\ is an array of data on a single grid. 
During each \MultiFab\ operation the \Fab~s composing that \MultiFab\ are distributed 
among the cores.  \MultiFab~s at each level of refinement are distributed 
independently.  The software supports two data distribution schemes, as well as a 
dynamic switching scheme that decides which approach to use based on the number of 
grids at a level and the number of processors.  The first scheme is based on a 
heuristic knapsack algorithm; the second is based on the use of a Morton-ordering 
space-filling curve.  \MultiFab\ operations are performed with an ``owner computes'' rule 
with each processor operating independently on its local data.  For operations that 
require data owned by other processors, the \MultiFab\ operations are preceded by a 
data exchange between processors to fill ghost cells.  Each processor contains 
meta-data that is needed 
to fully specify the geometry and processor assignments of the \MultiFab~s. At a 
minimum, this requires the storage of an array of boxes specifying the index space 
region for each AMR level of refinement.  The meta-data can thus be used to 
dynamically evaluate the necessary communication patterns for sharing data amongst 
processors, enabling us to optimize communications patterns within the algorithm.
One of the advantages of computing with fewer, larger grids in the hybrid 
OpenMP--MPI approach (see below) is that the size of the meta-data is substantially 
reduced.

\subsection{Hybrid Parallelism}

The basic parallelization strategy uses a hierarchical programming approach for 
multicore architectures based on both MPI and OpenMP. In the pure-MPI instantiation, at 
least one grid at each level is distributed to each core, and each core communicates 
with every other core using only MPI.  In the hybrid approach, where on each socket/node 
there are $n$ cores which all access the same memory, we can instead have one larger 
grid per socket/node, with the work associated with that grid distributed among the $n$ 
cores using OpenMP.

\subsection{Parallel I/O}

Data for checkpoints and analysis are written in a self-describing format that consists 
of a directory for each time step written. Checkpoint directories contain all necessary 
data to restart the calculation from that time step. Plotfile directories contain data 
for postprocessing, visualization, and analytics, which can be read using {\tt VisIt} or
{\tt AmrVis}, a customized visualization package developed at CCSE for visualizing 
data on AMR grids.  Within each checkpoint or plotfile directory is an ASCII header file and 
subdirectories for each AMR level. The header describes the AMR hierarchy, including 
number of levels, the grid boxes at each level, the problem size, refinement ratio 
between levels, step time, etc. Within each level directory are the \MultiFab\ files for 
each AMR level. Checkpoint and plotfile directories are written at user-specified intervals. 

Restarting a calculation can present some difficult issues for reading data efficiently. 
In the worst case, all processors would need data from all files. If multiple processors 
try to read from the same file at the same time, performance problems can result, with 
extreme cases causing file system thrashing. Since the number of files is generally not 
equal to the number of processors and each processor may need data from multiple files, 
input during restart is coordinated to efficiently read the data. Each data file is only 
opened by one processor at a time. The IOProcessor creates a database for mapping files 
to processors, coordinates the read queues, and interleaves reading its own data. Each 
processor reads all data it needs from the file it currently has open. The code tries to 
maintain the number of input streams to be equal to the number of files at all times. 
Checkpoint and plotfiles are portable to machines with a different byte ordering and 
precision from the machine that wrote the files. Byte order and precision translations 
are done automatically, if required, when the data is read.

\subsection{Scaling}

In Figure \ref{fig:scaling} we present weak scaling results for several of our codes on 
the Cray XT5 Jaguarpf at OLCF. Jaguarpf has two hex-core sockets on each node. We assign 
one MPI process per node and spawn a single thread on each of the 12 cores. Results are 
shown for our compressible astrophysics code, {\tt CASTRO}; the low Mach number code, 
{\tt MAESTRO}; and our low Mach number combustion code, {\tt LMC}. In the {\tt MAESTRO} 
and {\tt CASTRO} tests, we simulate a full spherical star on a 3D grid with one refined 
level (2 total levels).  {\tt LMC} is tested on a 3D methane flame with detailed chemistry 
using two refined levels. {\tt MAESTRO} and {\tt LMC} scale well to 50K-100K cores, 
whereas {\tt CASTRO} scales well to over 200K cores. The overall scaling behavior 
for {\tt MAESTRO} and {\tt LMC} is not as close to ideal as that of {\tt CASTRO} 
due to the communication-intensive linear solves performed at each time step. However, 
these low Mach number codes are able to take a much larger time step than explicit 
compressible formulations in the low Mach number regime. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\centering
\includegraphics[width=3in]{./Overview/castro_scaling}
\includegraphics[width=3in]{./Overview/maestro_scaling}
\includegraphics[width=3in]{./Overview/lmc_scaling}
\caption{\label{fig:scaling}Weak scaling results for {\tt CASTRO}, {\tt MAESTRO}, and
{\tt LMC} on the Cray XT5 Jaguarpf at OLCF.}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data Structure Details}

\BoxLib\ contains the most fundamental objects used to construct parallel
block-structured AMR applications, where different regions of the domain 
can have different spatial resolutions. 
At each level of refinement, the region covered by that level is broken
into boxes, or grids.  The entire computational domain is covered by
the coarsest (base) level of refinement, often called level $\ell=0$. 
Higher levels of refinement have cells that are finer by a ``refinement ratio''
of either 2 or 4.  The grids are properly nested in the sense that the union 
of grids at level $\ell+1$ is contained in the union of grids at level $\ell$.
Furthermore, the containment is strict in the sense that, except at physical 
boundaries, the level $\ell$ grids are large enough to guarantee that there is
a border at least $n_{\rm proper}$ level $\ell$ cells wide surrounding each level
$\ell +1$ grid (grids at all levels are allowed to extend to the physical
boundaries so the proper nesting is not strict there).
For parallel computations, the boxes are distributed to processors in
a fashion designed to put roughly equal amounts of work on each
processor (load balancing).

On a grid, the data can be stored at cell-centers, on a faces, or
on the corners.  In \BoxLib, data that is on an face is termed `nodal'
in that direction (see Figure~\ref{fig:dataloc}).  Data that is on the
corners is nodal in all spatial directions.  In our \BoxLib\ applications, 
the state data (velocity, density, species, $\ldots$) is generally
cell-centered.  Fluxes are nodal in the direction they represent.
A few quantities are nodal in all directions (e.g.\ the pressure in
the low Mach number projection methods).  
Note that when a C++ \BoxLib\ application is compiled and linked,
the number of spatial dimensions (1, 2, or 3), {\tt DIM},
of the code must be specified.  The code that will be
built is specifically designed to run only with that number of dimensions.
(This is unlike the fortran \BoxLib\ data structures in which we build
dimension-independent code at compile-time.)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\centering
\includegraphics[width=6.5in]{./Overview/data_loc2}
\caption{\label{fig:dataloc} Some of the different data-centerings:
(a) cell-centered, (b) nodal in the $x$-direction only, and (c) nodal in
both the $x$- and $y$-directions.  Note that for nodal data, the
integer index corresponds to the lower boundary in that direction.
In each of these centerings, the red point has the same indices:\ (1,2).
Not shown is the case where data is nodal in the $y$-direction only.  
Note that \BoxLib\ uses $0$-based indexing.}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To simplify the description of the underlying AMR grid, \BoxLib\
provides a number of classes.  We now briefly summarize some of the major
classes.

\subsection{\IntVect}

\IntVect~s are {\tt DIM}-tuples of integers that are used to define
indices in space.  An example of an \IntVect\ in 2D would
be (3,5).

\subsection{\BoxType}

A \BoxType\ is simply a rectangular domain in space.  Note that \BoxType~es
do not hold any data themselves. A \BoxType\ contains
the indices of its low end and high end, {\tt lo} and {\tt hi}.
In C++ \BoxLib\, a \BoxType\ also
contains an {\tt IndexType} (cell-centered, face-centered, or nodal) for each
dimension.  In fortran \BoxLib\, a \BoxType\ also contains the dimensionality
of the \BoxType.

The computational domain is divided into boxes.  The collection of
boxes with the same resolution comprise a level.
Figure~\ref{fig:boxes} shows three boxes at the same level of
refinement.  The position of the boxes is with respect to a global
index space at that level.  For example, box 1 in the figure has 
{\tt lo} = (3,7) and {\tt hi} = (9,12).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\centering
\includegraphics[width=4.0in]{./Overview/index_grid2}
\caption{\label{fig:boxes} Three boxes that comprise a single level.
At this resolution, the domain is 20$\times$18 cells.}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In C++ \BoxLib\, for a \BoxType\ {\tt bx},
you can access the indices using
\begin{itemize}
\item {{\tt IntVect se = bx.smallEnd();} // for box 1 above this would return
      the \IntVect\ (3,7)}
\item {{\tt IntVect be = bx.bigEnd();} // for box 1 above this would return 
      the \IntVect\ (9,12)}
\end{itemize}

\subsection{\BoxArray}

A \BoxArray\ is an array of boxes.   The size of the array is the 
number of boxes in the \BoxArray.

\subsection{\FArrayBox}

A \FArrayBox\ (or \Fab) is a ``fortran array box'' that holds data.  It contains the
\BoxType\ that it is built on as well as a pointer to the data 
that can be sent to a Fortran routine.  In \BoxLib\, we don't usually deal with 
\Fab~s alone, but rather
through \MultiFab~s, described next.

\subsection{\MultiFab}

A \MultiFab\ is a collection of \Fab~s at the same level of
refinement.  A \MultiFab\ is defined using a \BoxArray,
number of components, and number of ``ghost'' calls that each \Fab\
will have.  A \MultiFab\ has a "valid" region that is defined by 
the \BoxArray.  Each \Fab\ in the \MultiFab\ is built large enough 
to hold valid data and ghost data, and thus the \BoxType\ associated with
each \Fab\ is a grown version of the corresponding \BoxType\ from the \BoxArray.
Thus, a \Fab\ has no concept 
of ghost cells, it merely has a single box that identifies it.  
If we have a \BoxArray, {\tt myba}, then in C++ \BoxLib\ we could 
define a \MultiFab\ as:
\begin{verbatim}
MultiFab mymf(myba,2,1);
\end{verbatim}
This \MultiFab\ has two components of data and each \Fab\ in the \MultiFab\ contains 
ghost cells one row wide in all directions outside the box from the \BoxArray.



\section{\BoxLib\ Directory Structure}

\BoxLib\ is the base directory in a hierarchy of subdirectories that
support parallel, block-structured AMR applications in C++ and fortran.
A schematic of the \BoxLib\ directory structure is shown in Figure 
\ref{fig:boxlib_directory}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\centering
\includegraphics[width=6.5in]{./Overview/boxlib_directory_bw2}
\caption{\label{fig:boxlib_directory}\BoxLib\ directory structure.}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}

\item {\tt Docs/}

Contains the \BoxLib\ User's Guide.

\item {\tt Src/}

  \begin{itemize}

    \item {\tt C\_AMRLib/}
    \item {\tt C\_BaseLib/}
    \item {\tt C\_BoundaryLib/}
    \item {\tt F\_BaseLib/}
    \item {\tt LinearSolvers/}

    \begin{itemize}

      \item {\tt C\_CellMG/}
      \item {\tt C\_NodalMG/}
      \item {\tt C\_TensorMG/}
      \item {\tt C\_to\_F\_MG/}
      \item {\tt F\_MG/}

    \end{itemize}

  \end{itemize}

\item {\tt Tests/}

  \begin{itemize}

  \item {\tt C\_BaseLib/}
  \item {\tt F\_BaseLib/}
  \item {\tt LinearSolvers/}

  \end{itemize}

\item {\tt Tools/}

  \begin{itemize}

  \item {\tt C\_mk/}

  The generic Makefiles that store the C++ compilation flags for
  various platforms.

  \item {\tt C\_scripts/}

  Some simple scripts that are useful for building, running,
  maintaining codes in \BoxLib.

  \end{itemize}

  \item {\tt C\_Util/}
  \item {\tt F\_mk/}
  \item {\tt F\_scripts/}

\item {\tt Tutorials/}

\end{itemize}
