[main]
sourceDir      = /work/zingale/CASTRO/
testTopDir     = /work/zingale/CASTRO/
compareToolDir = /work/zingale/CASTRO/Parallel/util/Convergence/
helmeosDir     = /work/zingale/CASTRO/fParallel/extern/helmeos/

sourceTree = Parallel

# suiteName is the name prepended to all output directories
suiteName = Castro


# MPIcommand should use the placeholders:
#   @host@ to indicate where to put the hostname to run on
#   @nprocs@ to indicate where to put the number of processors
#   @command@ to indicate where to put the command to run
#
# only tests with useMPI = 1 will run in parallel
# nprocs is problem dependent and specified in the individual problem
# sections.

MPIcommand = mpiexec -host @host@ -n @nprocs@ @command@
MPIhost = node1


# individual problems follow

[Sod-x]
buildDir = Parallel/Castro/Sod/
inputFile = inputs-sod-x
probinFile = probin-sod-x
needs_helmeos = 0
dim = 3

[Sod-y]
buildDir = Parallel/Castro/Sod/
inputFile = inputs-sod-y
probinFile = probin-sod-y
needs_helmeos = 0
dim = 3

[Sod-z]
buildDir = Parallel/Castro/Sod/
inputFile = inputs-sod-z
probinFile = probin-sod-z
needs_helmeos = 0
dim = 3

[Sedov-2d]
buildDir = Parallel/Castro/Sedov/
inputFile = inputs.2d.sph_in_cylcoords
probinFile = probin.2d.sph_in_cylcoords
needs_helmeos = 0
dim = 2

[lightfront-1d]
buildDir = Parallel/Castro/RadTests/
inputFile = light_front_1d/inputs_xp
probinFile = light_front_1d/probin_xp
needs_helmeos = 1
dim = 1
useMPI = 1
numprocs = 1
 



